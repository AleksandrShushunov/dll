{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%matplotlib inline\n\nfrom io import open\nimport unicodedata\nimport string\nimport re\nimport random\n\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nfrom torch import optim\nimport torch.nn.functional as F\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"id":"MIEGXF8oM9tt","execution":{"iopub.status.busy":"2023-09-23T18:19:41.467749Z","iopub.execute_input":"2023-09-23T18:19:41.468394Z","iopub.status.idle":"2023-09-23T18:19:45.454776Z","shell.execute_reply.started":"2023-09-23T18:19:41.468330Z","shell.execute_reply":"2023-09-23T18:19:45.453652Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"!wget https://www.manythings.org/anki/rus-eng.zip\n!unzip rus-eng.zip","metadata":{"id":"8UKlPFcBNZl5","outputId":"c4eb79b7-0097-427e-f25c-a5f5e9473449","execution":{"iopub.status.busy":"2023-09-23T18:19:45.457797Z","iopub.execute_input":"2023-09-23T18:19:45.458733Z","iopub.status.idle":"2023-09-23T18:19:49.429012Z","shell.execute_reply.started":"2023-09-23T18:19:45.458692Z","shell.execute_reply":"2023-09-23T18:19:49.427336Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"--2023-09-23 18:19:46--  https://www.manythings.org/anki/rus-eng.zip\nResolving www.manythings.org (www.manythings.org)... 173.254.30.110\nConnecting to www.manythings.org (www.manythings.org)|173.254.30.110|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 15824155 (15M) [application/zip]\nSaving to: ‘rus-eng.zip’\n\nrus-eng.zip         100%[===================>]  15.09M  19.8MB/s    in 0.8s    \n\n2023-09-23 18:19:47 (19.8 MB/s) - ‘rus-eng.zip’ saved [15824155/15824155]\n\nArchive:  rus-eng.zip\n  inflating: rus.txt                 \n  inflating: _about.txt              \n","output_type":"stream"}]},{"cell_type":"code","source":"!head rus.txt","metadata":{"id":"twIcAJnyRkW-","outputId":"aae61acf-df6c-4443-8eaa-61a0be531bfa","execution":{"iopub.status.busy":"2023-09-23T18:19:49.431365Z","iopub.execute_input":"2023-09-23T18:19:49.431807Z","iopub.status.idle":"2023-09-23T18:19:50.559511Z","shell.execute_reply.started":"2023-09-23T18:19:49.431764Z","shell.execute_reply":"2023-09-23T18:19:50.558092Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Go.\tМарш!\tCC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #1159202 (shanghainese)\nGo.\tИди.\tCC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #5898247 (marafon)\nGo.\tИдите.\tCC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #5898250 (marafon)\nHi.\tЗдравствуйте.\tCC-BY 2.0 (France) Attribution: tatoeba.org #538123 (CM) & #402127 (odexed)\nHi.\tПривет!\tCC-BY 2.0 (France) Attribution: tatoeba.org #538123 (CM) & #466968 (katjka)\nHi.\tХай.\tCC-BY 2.0 (France) Attribution: tatoeba.org #538123 (CM) & #467233 (timsa)\nHi.\tЗдрасте.\tCC-BY 2.0 (France) Attribution: tatoeba.org #538123 (CM) & #3803577 (marafon)\nHi.\tЗдоро́во!\tCC-BY 2.0 (France) Attribution: tatoeba.org #538123 (CM) & #3854188 (marafon)\nHi.\tПриветик!\tCC-BY 2.0 (France) Attribution: tatoeba.org #538123 (CM) & #7234283 (marafon)\nRun!\tБеги!\tCC-BY 2.0 (France) Attribution: tatoeba.org #906328 (papabear) & #1569978 (Biga)\n","output_type":"stream"}]},{"cell_type":"code","source":"SOS_token = 0\nEOS_token = 1\n\n\nclass Lang:\n    def __init__(self, name):\n        self.name = name\n        self.word2index = {}\n        self.word2count = {}\n        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n        self.n_words = 2  # Count SOS and EOS\n\n    def addSentence(self, sentence):\n        for word in sentence.split(' '):\n            self.addWord(word)\n\n    def addWord(self, word):\n        if word not in self.word2index:\n            self.word2index[word] = self.n_words\n            self.word2count[word] = 1\n            self.index2word[self.n_words] = word\n            self.n_words += 1\n        else:\n            self.word2count[word] += 1","metadata":{"id":"kyNnJyruM9t1","execution":{"iopub.status.busy":"2023-09-23T18:19:50.565373Z","iopub.execute_input":"2023-09-23T18:19:50.570288Z","iopub.status.idle":"2023-09-23T18:19:50.585448Z","shell.execute_reply.started":"2023-09-23T18:19:50.570239Z","shell.execute_reply":"2023-09-23T18:19:50.583000Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Turn a Unicode string to plain ASCII, thanks to\n# http://stackoverflow.com/a/518232/2809427\ndef unicodeToAscii(s):\n    return ''.join(\n        c for c in unicodedata.normalize('NFD', s)\n        if unicodedata.category(c) != 'Mn'\n    )\n\n# Lowercase, trim, and remove non-letter characters\n\n\ndef normalizeString(s):\n    s = unicodeToAscii(s.lower().strip())\n    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n    s = re.sub(r\"[^a-zA-Z-А-аЯ-я.!?]+\", r\" \", s)\n    return s","metadata":{"id":"FXKs8j4bM9t6","execution":{"iopub.status.busy":"2023-09-23T18:19:50.587248Z","iopub.execute_input":"2023-09-23T18:19:50.588052Z","iopub.status.idle":"2023-09-23T18:19:50.610965Z","shell.execute_reply.started":"2023-09-23T18:19:50.588003Z","shell.execute_reply":"2023-09-23T18:19:50.609321Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def readLangs(lang1 = 'eng', lang2 = 'rus', reverse=False):\n    print(\"Reading lines...\")\n    \n    # Read the file and split into lines\n    lines = open('rus.txt', encoding='utf-8').\\\n        read().strip().split('\\n')\n\n    # Split every line into pairs and normalize\n    pairs = [[normalizeString(s) for s in l.split('\\t')[:2]] for l in lines]\n\n    # Reverse pairs, make Lang instances\n    if reverse:\n        pairs = [list(reversed(p)) for p in pairs]\n        input_lang = Lang(lang2)\n        output_lang = Lang(lang1)\n    else:\n        input_lang = Lang(lang1)\n        output_lang = Lang(lang2)\n\n    return input_lang, output_lang, pairs","metadata":{"id":"D8T4VxZeM9t-","execution":{"iopub.status.busy":"2023-09-23T18:19:50.613134Z","iopub.execute_input":"2023-09-23T18:19:50.613577Z","iopub.status.idle":"2023-09-23T18:19:50.636451Z","shell.execute_reply.started":"2023-09-23T18:19:50.613534Z","shell.execute_reply":"2023-09-23T18:19:50.633640Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"MAX_LENGTH = 10\n\neng_prefixes = (\n    \"i am \", \"i m \",\n    \"he is\", \"he s \",\n    \"she is\", \"she s\",\n    \"you are\", \"you re \",\n    \"we are\", \"we re \",\n    \"they are\", \"they re \"\n)\n\n\ndef filterPair(p):\n    return len(p[0].split(' ')) < MAX_LENGTH and \\\n        len(p[1].split(' ')) < MAX_LENGTH and \\\n        p[1].startswith(eng_prefixes)\n\n\ndef filterPairs(pairs):\n    return [pair for pair in pairs if filterPair(pair)]","metadata":{"id":"eBOwgEBdM9uB","execution":{"iopub.status.busy":"2023-09-23T18:19:50.638864Z","iopub.execute_input":"2023-09-23T18:19:50.639817Z","iopub.status.idle":"2023-09-23T18:19:50.649390Z","shell.execute_reply.started":"2023-09-23T18:19:50.639776Z","shell.execute_reply":"2023-09-23T18:19:50.648040Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def prepareData(lang1, lang2, reverse=False):\n    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n    print(\"Read %s sentence pairs\" % len(pairs))\n    pairs = filterPairs(pairs)\n    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n    print(\"Counting words...\")\n    for pair in pairs:\n        input_lang.addSentence(pair[0])\n        output_lang.addSentence(pair[1])\n    print(\"Counted words:\")\n    print(input_lang.name, input_lang.n_words)\n    print(output_lang.name, output_lang.n_words)\n    return input_lang, output_lang, pairs\n\n\ninput_lang, output_lang, pairs = prepareData('eng', 'rus', True)\nprint(random.choice(pairs))","metadata":{"id":"6dZOGjd5M9uE","outputId":"0cdd3a7f-2ac8-4872-8a81-6101d0bdd0a9","execution":{"iopub.status.busy":"2023-09-23T18:19:50.653296Z","iopub.execute_input":"2023-09-23T18:19:50.654830Z","iopub.status.idle":"2023-09-23T18:20:19.796084Z","shell.execute_reply.started":"2023-09-23T18:19:50.654788Z","shell.execute_reply":"2023-09-23T18:20:19.794775Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Reading lines...\nRead 479223 sentence pairs\nTrimmed to 27844 sentence pairs\nCounting words...\nCounted words:\nrus 10125\neng 4320\n['я собираюсь купить новую машину .', 'i am going to buy a new car .']\n","output_type":"stream"}]},{"cell_type":"markdown","source":"The Encoder\n-----------\n\n\n\n","metadata":{"id":"vgtWqznCM9uH"}},{"cell_type":"code","source":"class EncoderRNN(nn.Module):\n    def __init__(self, input_size, hidden_size):\n        super(EncoderRNN, self).__init__()\n        self.hidden_size = hidden_size\n\n        self.embedding = nn.Embedding(input_size, hidden_size)\n        self.gru = nn.GRU(hidden_size, hidden_size)\n\n    def forward(self, input, hidden):\n        embedded = self.embedding(input).view(1, 1, -1)\n        output = embedded\n        output, hidden = self.gru(output, hidden)\n        return output, hidden\n\n    def initHidden(self):\n        return torch.zeros(1, 1, self.hidden_size, device=device)","metadata":{"id":"m9vm9QBWM9uI","execution":{"iopub.status.busy":"2023-09-23T18:20:19.797953Z","iopub.execute_input":"2023-09-23T18:20:19.798481Z","iopub.status.idle":"2023-09-23T18:20:19.807630Z","shell.execute_reply.started":"2023-09-23T18:20:19.798440Z","shell.execute_reply":"2023-09-23T18:20:19.806217Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"The Decoder\n-----------\n\n\n","metadata":{"id":"FwLTlgSyM9uK"}},{"cell_type":"code","source":"class DecoderRNN(nn.Module):\n    def __init__(self, hidden_size, output_size):\n        super(DecoderRNN, self).__init__()\n        self.hidden_size = hidden_size\n\n        self.embedding = nn.Embedding(output_size, hidden_size)\n        self.gru = nn.GRU(hidden_size, hidden_size)\n        self.out = nn.Linear(hidden_size, output_size)\n        self.softmax = nn.LogSoftmax(dim=1)\n\n    def forward(self, input, hidden):\n        output = self.embedding(input).view(1, 1, -1)\n        output = F.relu(output)\n        output, hidden = self.gru(output, hidden)\n        output = self.softmax(self.out(output[0]))\n        return output, hidden\n\n    def initHidden(self):\n        return torch.zeros(1, 1, self.hidden_size, device=device)","metadata":{"id":"PFbuUL1LM9uL","execution":{"iopub.status.busy":"2023-09-23T18:20:19.813931Z","iopub.execute_input":"2023-09-23T18:20:19.815112Z","iopub.status.idle":"2023-09-23T18:20:19.826241Z","shell.execute_reply.started":"2023-09-23T18:20:19.815073Z","shell.execute_reply":"2023-09-23T18:20:19.824812Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"def indexesFromSentence(lang, sentence):\n    return [lang.word2index[word] for word in sentence.split(' ')]\n\n\ndef tensorFromSentence(lang, sentence):\n    indexes = indexesFromSentence(lang, sentence)\n    indexes.append(EOS_token)\n    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n\n\ndef tensorsFromPair(pair):\n    input_tensor = tensorFromSentence(input_lang, pair[0])\n    target_tensor = tensorFromSentence(output_lang, pair[1])\n    return (input_tensor, target_tensor)","metadata":{"id":"z6gGPtXFM9uQ","execution":{"iopub.status.busy":"2023-09-23T18:20:19.828071Z","iopub.execute_input":"2023-09-23T18:20:19.828484Z","iopub.status.idle":"2023-09-23T18:20:19.837460Z","shell.execute_reply.started":"2023-09-23T18:20:19.828438Z","shell.execute_reply":"2023-09-23T18:20:19.836266Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"teacher_forcing_ratio = 0.5\n\n\ndef train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n    encoder_hidden = encoder.initHidden()\n\n    encoder_optimizer.zero_grad()\n    decoder_optimizer.zero_grad()\n\n    input_length = input_tensor.size(0)\n    target_length = target_tensor.size(0)\n\n    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n\n    loss = 0\n\n    for ei in range(input_length):\n        encoder_output, encoder_hidden = encoder(\n            input_tensor[ei], encoder_hidden)\n        encoder_outputs[ei] = encoder_output[0, 0]\n\n    decoder_input = torch.tensor([[SOS_token]], device=device)\n\n    decoder_hidden = encoder_hidden\n\n    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n\n    if use_teacher_forcing:\n        # Teacher forcing: Feed the target as the next input\n        for di in range(target_length):\n            decoder_output, decoder_hidden = decoder(\n                decoder_input, decoder_hidden)\n            loss += criterion(decoder_output, target_tensor[di])\n            decoder_input = target_tensor[di]  # Teacher forcing\n\n    else:\n        # Without teacher forcing: use its own predictions as the next input\n        for di in range(target_length):\n            decoder_output, decoder_hidden = decoder(\n                decoder_input, decoder_hidden)\n            topv, topi = decoder_output.topk(1)\n            decoder_input = topi.squeeze().detach()  # detach from history as input\n\n            loss += criterion(decoder_output, target_tensor[di])\n            if decoder_input.item() == EOS_token:\n                break\n\n    loss.backward()\n\n    encoder_optimizer.step()\n    decoder_optimizer.step()\n\n    return loss.item() / target_length","metadata":{"id":"8Fn8VDv8M9uS","execution":{"iopub.status.busy":"2023-09-23T18:20:19.839032Z","iopub.execute_input":"2023-09-23T18:20:19.840201Z","iopub.status.idle":"2023-09-23T18:20:19.853593Z","shell.execute_reply.started":"2023-09-23T18:20:19.840158Z","shell.execute_reply":"2023-09-23T18:20:19.852454Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"import time\nimport math\n\n\ndef asMinutes(s):\n    m = math.floor(s / 60)\n    s -= m * 60\n    return '%dm %ds' % (m, s)\n\n\ndef timeSince(since, percent):\n    now = time.time()\n    s = now - since\n    es = s / (percent)\n    rs = es - s\n    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))","metadata":{"id":"EKsdwPmSM9uU","execution":{"iopub.status.busy":"2023-09-23T18:20:19.855365Z","iopub.execute_input":"2023-09-23T18:20:19.856189Z","iopub.status.idle":"2023-09-23T18:20:19.866519Z","shell.execute_reply.started":"2023-09-23T18:20:19.856150Z","shell.execute_reply":"2023-09-23T18:20:19.865363Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n    start = time.time()\n    plot_losses = []\n    print_losses = []\n    print_loss_total = 0  # Reset every print_every\n    plot_loss_total = 0  # Reset every plot_every\n\n    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n    training_pairs = [tensorsFromPair(random.choice(pairs))\n                      for i in range(n_iters)]\n    criterion = nn.NLLLoss()\n\n    for iter in range(1, n_iters + 1):\n        training_pair = training_pairs[iter - 1]\n        input_tensor = training_pair[0]\n        target_tensor = training_pair[1]\n\n        loss = train(input_tensor, target_tensor, encoder,\n                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n        print_loss_total += loss\n        plot_loss_total += loss\n\n        if iter % print_every == 0:\n            print_loss_avg = print_loss_total / print_every\n            print_loss_total = 0\n            print_losses.append(print_loss_avg)\n            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n                                         iter, iter / n_iters * 100, print_loss_avg))\n\n        if iter % plot_every == 0:\n            plot_loss_avg = plot_loss_total / plot_every\n            plot_losses.append(plot_loss_avg)\n            plot_loss_total = 0\n\n    showPlot(plot_losses)\n    return print_losses","metadata":{"id":"C_z_k5IiM9uX","execution":{"iopub.status.busy":"2023-09-23T18:20:19.868590Z","iopub.execute_input":"2023-09-23T18:20:19.868968Z","iopub.status.idle":"2023-09-23T18:20:19.882338Z","shell.execute_reply.started":"2023-09-23T18:20:19.868932Z","shell.execute_reply":"2023-09-23T18:20:19.881200Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.switch_backend('agg')\nimport matplotlib.ticker as ticker\nimport numpy as np\n\n\ndef showPlot(points):\n    plt.figure()\n    fig, ax = plt.subplots()\n    # this locator puts ticks at regular intervals\n    loc = ticker.MultipleLocator(base=0.2)\n    ax.yaxis.set_major_locator(loc)\n    plt.plot(points)","metadata":{"id":"0JXG-RzCM9uZ","execution":{"iopub.status.busy":"2023-09-23T18:20:19.884104Z","iopub.execute_input":"2023-09-23T18:20:19.884610Z","iopub.status.idle":"2023-09-23T18:20:19.893031Z","shell.execute_reply.started":"2023-09-23T18:20:19.884450Z","shell.execute_reply":"2023-09-23T18:20:19.891680Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n    with torch.no_grad():\n        input_tensor = tensorFromSentence(input_lang, sentence)\n        input_length = input_tensor.size()[0]\n        encoder_hidden = encoder.initHidden()\n\n        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n\n        for ei in range(input_length):\n            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n                                                     encoder_hidden)\n            encoder_outputs[ei] += encoder_output[0, 0]\n\n        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n\n        decoder_hidden = encoder_hidden\n\n        decoded_words = []\n\n        for di in range(max_length):\n            decoder_output, decoder_hidden = decoder(\n                decoder_input, decoder_hidden)\n            topv, topi = decoder_output.data.topk(1)\n            if topi.item() == EOS_token:\n                decoded_words.append('<EOS>')\n                break\n            else:\n                decoded_words.append(output_lang.index2word[topi.item()])\n\n            decoder_input = topi.squeeze().detach()\n\n        return decoded_words","metadata":{"id":"3Bxf45h6M9ud","execution":{"iopub.status.busy":"2023-09-23T18:20:19.894863Z","iopub.execute_input":"2023-09-23T18:20:19.895472Z","iopub.status.idle":"2023-09-23T18:20:19.905724Z","shell.execute_reply.started":"2023-09-23T18:20:19.895427Z","shell.execute_reply":"2023-09-23T18:20:19.904689Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"def evaluateRandomly(encoder, decoder, n=10):\n    for i in range(n):\n        pair = random.choice(pairs)\n        print('>', pair[0])\n        print('=', pair[1])\n        output_words = evaluate(encoder, decoder, pair[0])\n        output_sentence = ' '.join(output_words)\n        print('<', output_sentence)\n        print('')","metadata":{"id":"1qUmQIGwM9uf","execution":{"iopub.status.busy":"2023-09-23T18:20:19.907243Z","iopub.execute_input":"2023-09-23T18:20:19.908002Z","iopub.status.idle":"2023-09-23T18:20:19.915435Z","shell.execute_reply.started":"2023-09-23T18:20:19.907937Z","shell.execute_reply":"2023-09-23T18:20:19.914412Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"hidden_size = 256\nencoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\ndecoder1 = DecoderRNN(hidden_size, output_lang.n_words).to(device)\n\nGRU = trainIters(encoder1, decoder1, 75000, print_every=5000)","metadata":{"id":"s_56t10oM9uh","outputId":"f456b0b8-fc35-4199-fb19-b45c2330bf72","execution":{"iopub.status.busy":"2023-09-23T18:20:19.917047Z","iopub.execute_input":"2023-09-23T18:20:19.917722Z","iopub.status.idle":"2023-09-23T18:35:34.803735Z","shell.execute_reply.started":"2023-09-23T18:20:19.917684Z","shell.execute_reply":"2023-09-23T18:35:34.802653Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"1m 8s (- 16m 5s) (5000 6%) 3.1146\n2m 8s (- 13m 52s) (10000 13%) 2.6256\n3m 6s (- 12m 25s) (15000 20%) 2.3421\n4m 6s (- 11m 17s) (20000 26%) 2.1445\n5m 6s (- 10m 13s) (25000 33%) 2.0145\n6m 7s (- 9m 10s) (30000 40%) 1.8395\n7m 7s (- 8m 8s) (35000 46%) 1.7564\n8m 7s (- 7m 6s) (40000 53%) 1.6396\n9m 7s (- 6m 4s) (45000 60%) 1.5584\n10m 7s (- 5m 3s) (50000 66%) 1.4903\n11m 7s (- 4m 2s) (55000 73%) 1.4264\n12m 7s (- 3m 1s) (60000 80%) 1.3373\n13m 7s (- 2m 1s) (65000 86%) 1.2824\n14m 7s (- 1m 0s) (70000 93%) 1.2237\n15m 8s (- 0m 0s) (75000 100%) 1.1650\n","output_type":"stream"}]},{"cell_type":"code","source":"evaluateRandomly(encoder1, decoder1)","metadata":{"id":"xEoEylSyM9uj","execution":{"iopub.status.busy":"2023-09-23T18:35:34.805410Z","iopub.execute_input":"2023-09-23T18:35:34.805791Z","iopub.status.idle":"2023-09-23T18:35:34.871516Z","shell.execute_reply.started":"2023-09-23T18:35:34.805755Z","shell.execute_reply":"2023-09-23T18:35:34.870247Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"> вы здесь в безопасности .\n= you re safe here .\n< you re safe here danger . <EOS>\n\n> я уверен что вы заслуживаете лучшего .\n= i m sure you deserve better .\n< i m sure you re found . . <EOS>\n\n> я удивлена что тома здесь нет .\n= i m surprised tom isn t here .\n< i m surprised tom isn t here here . <EOS>\n\n> тебе рано идти в армию .\n= you re too young to join the army .\n< you re too young to join the army . <EOS>\n\n> я сеичас ем .\n= i m eating now .\n< i m eating now . <EOS>\n\n> она в туалете .\n= she s in the bathroom .\n< she is in the . . <EOS>\n\n> я сделаю тебе укол .\n= i m going to give you an injection .\n< i m going to get you a . . <EOS>\n\n> ты чуть повыше меня .\n= you re a little taller than i am .\n< you re a little taller than i am . <EOS>\n\n> я безжалостныи .\n= i m ruthless .\n< i m sure . <EOS>\n\n> он такого же роста как мои отец .\n= he is as tall as my father .\n< he s as tall as my father . <EOS>\n\n","output_type":"stream"}]},{"cell_type":"code","source":"res = pd.DataFrame()\nres['1_GRU'] = GRU\nres","metadata":{"execution":{"iopub.status.busy":"2023-09-23T18:35:34.872955Z","iopub.execute_input":"2023-09-23T18:35:34.873429Z","iopub.status.idle":"2023-09-23T18:35:34.899725Z","shell.execute_reply.started":"2023-09-23T18:35:34.873391Z","shell.execute_reply":"2023-09-23T18:35:34.898420Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"       1_GRU\n0   3.114554\n1   2.625627\n2   2.342106\n3   2.144511\n4   2.014533\n5   1.839546\n6   1.756390\n7   1.639556\n8   1.558369\n9   1.490343\n10  1.426418\n11  1.337322\n12  1.282445\n13  1.223712\n14  1.165028","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>1_GRU</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3.114554</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2.625627</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2.342106</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2.144511</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2.014533</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>1.839546</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>1.756390</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>1.639556</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>1.558369</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>1.490343</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>1.426418</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>1.337322</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>1.282445</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>1.223712</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>1.165028</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"### Попробуем 2 рекуррентных слоя вместо 1","metadata":{}},{"cell_type":"code","source":"class EncoderRNN(nn.Module):\n    def __init__(self, input_size, hidden_size):\n        super(EncoderRNN, self).__init__()\n        self.hidden_size = hidden_size\n        self.embedding = nn.Embedding(input_size, hidden_size)\n        self.gru = nn.GRU(hidden_size, hidden_size,num_layers=2)\n    def forward(self, input, hidden):\n        embedded = self.embedding(input).view(1, 1, -1)\n        output = embedded\n        output, hidden = self.gru(output, hidden)\n        return output, hidden\n\n    def initHidden(self):\n        return torch.zeros(2, 1, self.hidden_size, device=device)","metadata":{"execution":{"iopub.status.busy":"2023-09-23T19:06:29.183073Z","iopub.execute_input":"2023-09-23T19:06:29.183466Z","iopub.status.idle":"2023-09-23T19:06:29.191750Z","shell.execute_reply.started":"2023-09-23T19:06:29.183436Z","shell.execute_reply":"2023-09-23T19:06:29.190613Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"class DecoderRNN(nn.Module):\n    def __init__(self, hidden_size, output_size):\n        super(DecoderRNN, self).__init__()\n        self.hidden_size = hidden_size\n\n        self.embedding = nn.Embedding(output_size, hidden_size)\n        self.gru = nn.GRU(hidden_size, hidden_size,num_layers=2)\n        self.out = nn.Linear(hidden_size, output_size)\n        self.softmax = nn.LogSoftmax(dim=1)\n\n    def forward(self, input, hidden):\n        output = self.embedding(input).view(1, 1, -1)\n        output = F.relu(output)\n        output, hidden = self.gru(output, hidden)\n        output = self.softmax(self.out(output[0]))\n        return output, hidden\n\n    def initHidden(self):\n        return torch.zeros(2, 1, self.hidden_size, device=device)","metadata":{"execution":{"iopub.status.busy":"2023-09-23T19:06:32.029351Z","iopub.execute_input":"2023-09-23T19:06:32.029728Z","iopub.status.idle":"2023-09-23T19:06:32.038956Z","shell.execute_reply.started":"2023-09-23T19:06:32.029698Z","shell.execute_reply":"2023-09-23T19:06:32.037816Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"hidden_size = 256\nencoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\ndecoder1 = DecoderRNN(hidden_size, output_lang.n_words).to(device)\n\nGRU_2 = trainIters(encoder1, decoder1, 75000, print_every=5000)","metadata":{"execution":{"iopub.status.busy":"2023-09-23T19:06:36.358294Z","iopub.execute_input":"2023-09-23T19:06:36.358698Z","iopub.status.idle":"2023-09-23T19:24:05.755105Z","shell.execute_reply.started":"2023-09-23T19:06:36.358665Z","shell.execute_reply":"2023-09-23T19:24:05.753860Z"},"trusted":true},"execution_count":49,"outputs":[{"name":"stdout","text":"1m 14s (- 17m 25s) (5000 6%) 3.1487\n2m 23s (- 15m 33s) (10000 13%) 2.6643\n3m 34s (- 14m 17s) (15000 20%) 2.4316\n4m 43s (- 13m 0s) (20000 26%) 2.2138\n5m 52s (- 11m 45s) (25000 33%) 2.0863\n7m 1s (- 10m 31s) (30000 40%) 1.9435\n8m 9s (- 9m 18s) (35000 46%) 1.8108\n9m 17s (- 8m 7s) (40000 53%) 1.7151\n10m 26s (- 6m 57s) (45000 60%) 1.6104\n11m 37s (- 5m 48s) (50000 66%) 1.5421\n12m 47s (- 4m 39s) (55000 73%) 1.4435\n13m 57s (- 3m 29s) (60000 80%) 1.3908\n15m 7s (- 2m 19s) (65000 86%) 1.2992\n16m 18s (- 1m 9s) (70000 93%) 1.2270\n17m 28s (- 0m 0s) (75000 100%) 1.1931\n","output_type":"stream"}]},{"cell_type":"code","source":"evaluateRandomly(encoder1, decoder1)","metadata":{"execution":{"iopub.status.busy":"2023-09-23T19:35:11.445908Z","iopub.execute_input":"2023-09-23T19:35:11.446390Z","iopub.status.idle":"2023-09-23T19:35:11.511911Z","shell.execute_reply.started":"2023-09-23T19:35:11.446357Z","shell.execute_reply":"2023-09-23T19:35:11.510638Z"},"trusted":true},"execution_count":50,"outputs":[{"name":"stdout","text":"> он американец .\n= he is american .\n< he is going to <EOS>\n\n> вы ужасны .\n= you re terrible .\n< you re getting . <EOS>\n\n> ты докапываешься до мелочеи .\n= you re splitting hairs .\n< you re going to the . . <EOS>\n\n> он младше меня .\n= he s younger than me .\n< he is younger than me . <EOS>\n\n> ты ведь дочь тома ?\n= you re tom s daughter aren t you ?\n< you re tom s daughter aren t you ? <EOS>\n\n> он пацифист .\n= he s a pacifist .\n< he s a . . <EOS>\n\n> прости если задел твои чувства .\n= i m sorry if i hurt your feelings .\n< i m sorry if i your your your . <EOS>\n\n> вы белая как простыня .\n= you re white as a sheet .\n< you re as white a sheet a sheet . <EOS>\n\n> нам так весело .\n= we re having so much fun .\n< we re so kind . <EOS>\n\n> она хорошо целуется .\n= she s a good kisser .\n< she s well . <EOS>\n\n","output_type":"stream"}]},{"cell_type":"code","source":"res['2_GRU'] = GRU_2\nres","metadata":{"execution":{"iopub.status.busy":"2023-09-23T19:35:43.238305Z","iopub.execute_input":"2023-09-23T19:35:43.238732Z","iopub.status.idle":"2023-09-23T19:35:43.257461Z","shell.execute_reply.started":"2023-09-23T19:35:43.238700Z","shell.execute_reply":"2023-09-23T19:35:43.255040Z"},"trusted":true},"execution_count":51,"outputs":[{"execution_count":51,"output_type":"execute_result","data":{"text/plain":"       1_GRU     2_GRU\n0   3.114554  3.148655\n1   2.625627  2.664298\n2   2.342106  2.431606\n3   2.144511  2.213844\n4   2.014533  2.086283\n5   1.839546  1.943527\n6   1.756390  1.810832\n7   1.639556  1.715083\n8   1.558369  1.610350\n9   1.490343  1.542077\n10  1.426418  1.443541\n11  1.337322  1.390830\n12  1.282445  1.299243\n13  1.223712  1.226997\n14  1.165028  1.193117","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>1_GRU</th>\n      <th>2_GRU</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3.114554</td>\n      <td>3.148655</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2.625627</td>\n      <td>2.664298</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2.342106</td>\n      <td>2.431606</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2.144511</td>\n      <td>2.213844</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2.014533</td>\n      <td>2.086283</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>1.839546</td>\n      <td>1.943527</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>1.756390</td>\n      <td>1.810832</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>1.639556</td>\n      <td>1.715083</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>1.558369</td>\n      <td>1.610350</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>1.490343</td>\n      <td>1.542077</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>1.426418</td>\n      <td>1.443541</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>1.337322</td>\n      <td>1.390830</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>1.282445</td>\n      <td>1.299243</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>1.223712</td>\n      <td>1.226997</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>1.165028</td>\n      <td>1.193117</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"### Попробуем GRU слой заменить на LSTM","metadata":{}},{"cell_type":"code","source":"class EncoderRNN(nn.Module):\n    def __init__(self, input_size, hidden_size):\n        super(EncoderRNN, self).__init__()\n        self.hidden_size = hidden_size\n        self.embedding = nn.Embedding(input_size, hidden_size)\n        self.LSTM = nn.LSTM(hidden_size, hidden_size)\n\n    def forward(self, input, hidden):\n        embedded = self.embedding(input).view(1, 1, -1)\n        output = embedded\n        output, hidden = self.LSTM(output, hidden)\n        return output, hidden\n\n    def initHidden(self):\n        h = torch.zeros(1, 1, self.hidden_size, device=device)\n        c = torch.zeros(1, 1, self.hidden_size, device=device)\n        return h,c","metadata":{"execution":{"iopub.status.busy":"2023-09-23T20:07:15.444760Z","iopub.execute_input":"2023-09-23T20:07:15.445215Z","iopub.status.idle":"2023-09-23T20:07:15.453712Z","shell.execute_reply.started":"2023-09-23T20:07:15.445182Z","shell.execute_reply":"2023-09-23T20:07:15.452644Z"},"trusted":true},"execution_count":83,"outputs":[]},{"cell_type":"code","source":"class DecoderRNN(nn.Module):\n    def __init__(self, hidden_size, output_size):\n        super(DecoderRNN, self).__init__()\n        self.hidden_size = hidden_size\n        \n        self.embedding = nn.Embedding(output_size, hidden_size)\n        self.LSTM = nn.LSTM(hidden_size, hidden_size)\n        self.out = nn.Linear(hidden_size, output_size)\n        self.softmax = nn.LogSoftmax(dim=1)\n\n    def forward(self, input, hidden):\n        output = self.embedding(input).view(1, 1, -1)\n        output = F.relu(output)\n        output, hidden = self.LSTM(output, hidden)\n        output = self.softmax(self.out(output[0]))\n        return output, hidden\n\n    def initHidden(self):\n        h = torch.zeros(1, 1, self.hidden_size, device=device)\n        c = torch.zeros(1, 1, self.hidden_size, device=device)\n        return h,c","metadata":{"execution":{"iopub.status.busy":"2023-09-23T20:07:18.596533Z","iopub.execute_input":"2023-09-23T20:07:18.596930Z","iopub.status.idle":"2023-09-23T20:07:18.607949Z","shell.execute_reply.started":"2023-09-23T20:07:18.596900Z","shell.execute_reply":"2023-09-23T20:07:18.606704Z"},"trusted":true},"execution_count":84,"outputs":[]},{"cell_type":"code","source":"hidden_size = 256\nencoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\ndecoder1 = DecoderRNN(hidden_size, output_lang.n_words).to(device)\n\nLSTM_2 = trainIters(encoder1, decoder1, 75000, print_every=5000)","metadata":{"execution":{"iopub.status.busy":"2023-09-23T20:07:20.760962Z","iopub.execute_input":"2023-09-23T20:07:20.761364Z","iopub.status.idle":"2023-09-23T20:23:17.934683Z","shell.execute_reply.started":"2023-09-23T20:07:20.761333Z","shell.execute_reply":"2023-09-23T20:23:17.933596Z"},"trusted":true},"execution_count":85,"outputs":[{"name":"stdout","text":"1m 6s (- 15m 37s) (5000 6%) 3.2031\n2m 9s (- 14m 1s) (10000 13%) 2.7595\n3m 12s (- 12m 49s) (15000 20%) 2.5654\n4m 15s (- 11m 43s) (20000 26%) 2.3922\n5m 18s (- 10m 36s) (25000 33%) 2.2260\n6m 21s (- 9m 32s) (30000 40%) 2.1183\n7m 25s (- 8m 28s) (35000 46%) 1.9887\n8m 28s (- 7m 25s) (40000 53%) 1.9049\n9m 32s (- 6m 21s) (45000 60%) 1.7934\n10m 35s (- 5m 17s) (50000 66%) 1.7471\n11m 41s (- 4m 14s) (55000 73%) 1.6513\n12m 45s (- 3m 11s) (60000 80%) 1.5865\n13m 49s (- 2m 7s) (65000 86%) 1.5224\n14m 53s (- 1m 3s) (70000 93%) 1.4529\n15m 56s (- 0m 0s) (75000 100%) 1.4006\n","output_type":"stream"}]},{"cell_type":"code","source":"evaluateRandomly(encoder1, decoder1)","metadata":{"execution":{"iopub.status.busy":"2023-09-23T20:24:03.097660Z","iopub.execute_input":"2023-09-23T20:24:03.098099Z","iopub.status.idle":"2023-09-23T20:24:03.164287Z","shell.execute_reply.started":"2023-09-23T20:24:03.098063Z","shell.execute_reply":"2023-09-23T20:24:03.163055Z"},"trusted":true},"execution_count":86,"outputs":[{"name":"stdout","text":"> она очень быстрая .\n= she is very fast .\n< she is very fast . <EOS>\n\n> вы в два раза старше меня .\n= you re twice as old as i am .\n< you re twice as old as i am . <EOS>\n\n> он худощавыи .\n= he s skinny .\n< he is a . . <EOS>\n\n> я рад что люди ее видели .\n= i m glad people saw it .\n< i m glad it saw it . <EOS>\n\n> вы настоящии джентльмен .\n= you re a true gentleman .\n< you re a real girl . <EOS>\n\n> мне стыдно за мое прошлое .\n= i m ashamed of my past .\n< i m ashamed of my own . <EOS>\n\n> у нее плохое настроение .\n= she is in a bad mood .\n< she is in a bad mood . <EOS>\n\n> они довольно новые .\n= they re pretty new .\n< they re pretty pretty . <EOS>\n\n> она укладывает детеи .\n= she s putting the children to bed .\n< she is a young . <EOS>\n\n> я начну сначала .\n= i m going to start over .\n< i m going to take a . . <EOS>\n\n","output_type":"stream"}]},{"cell_type":"code","source":"res['LSTM'] = LSTM_2\nres","metadata":{"execution":{"iopub.status.busy":"2023-09-23T20:24:55.558223Z","iopub.execute_input":"2023-09-23T20:24:55.558647Z","iopub.status.idle":"2023-09-23T20:24:55.574282Z","shell.execute_reply.started":"2023-09-23T20:24:55.558614Z","shell.execute_reply":"2023-09-23T20:24:55.573010Z"},"trusted":true},"execution_count":87,"outputs":[{"execution_count":87,"output_type":"execute_result","data":{"text/plain":"       1_GRU     2_GRU      LSTM\n0   3.114554  3.148655  3.203134\n1   2.625627  2.664298  2.759481\n2   2.342106  2.431606  2.565408\n3   2.144511  2.213844  2.392207\n4   2.014533  2.086283  2.226007\n5   1.839546  1.943527  2.118267\n6   1.756390  1.810832  1.988666\n7   1.639556  1.715083  1.904871\n8   1.558369  1.610350  1.793425\n9   1.490343  1.542077  1.747118\n10  1.426418  1.443541  1.651344\n11  1.337322  1.390830  1.586517\n12  1.282445  1.299243  1.522363\n13  1.223712  1.226997  1.452921\n14  1.165028  1.193117  1.400623","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>1_GRU</th>\n      <th>2_GRU</th>\n      <th>LSTM</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3.114554</td>\n      <td>3.148655</td>\n      <td>3.203134</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2.625627</td>\n      <td>2.664298</td>\n      <td>2.759481</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2.342106</td>\n      <td>2.431606</td>\n      <td>2.565408</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2.144511</td>\n      <td>2.213844</td>\n      <td>2.392207</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2.014533</td>\n      <td>2.086283</td>\n      <td>2.226007</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>1.839546</td>\n      <td>1.943527</td>\n      <td>2.118267</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>1.756390</td>\n      <td>1.810832</td>\n      <td>1.988666</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>1.639556</td>\n      <td>1.715083</td>\n      <td>1.904871</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>1.558369</td>\n      <td>1.610350</td>\n      <td>1.793425</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>1.490343</td>\n      <td>1.542077</td>\n      <td>1.747118</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>1.426418</td>\n      <td>1.443541</td>\n      <td>1.651344</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>1.337322</td>\n      <td>1.390830</td>\n      <td>1.586517</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>1.282445</td>\n      <td>1.299243</td>\n      <td>1.522363</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>1.223712</td>\n      <td>1.226997</td>\n      <td>1.452921</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>1.165028</td>\n      <td>1.193117</td>\n      <td>1.400623</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}